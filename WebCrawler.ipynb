{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WebCrawler.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StTronn/website_cat_api/blob/master/WebCrawler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9oZtPkQOMeg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt0nahsnblOo",
        "colab_type": "text"
      },
      "source": [
        "# Filter Cisco Rank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzeu2VOjSMi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -P /content/drive/My\\ Drive/ -c \"http://s3-us-west-1.amazonaws.com/umbrella-static/top-1m-2020-01-01.csv.zip\"\n",
        "!unzip -q \"/content/drive/My Drive/top-1m-2020-01-01.csv.zip\" -d \"/content/drive/My Drive/Site Data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mCeffbVY9AR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import sys\n",
        "\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "\n",
        "with open(\"/content/drive/My Drive/Site Data/top-1m.csv\") as csvfile:\n",
        "  csv_reader = csv.reader(csvfile)\n",
        "  urls = list(csv_reader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rqv27kYcd0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install tldextract"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXO2ol7OlGPW",
        "colab_type": "code",
        "outputId": "0028a571-0a29-4a03-a21f-04d24ba73adb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tldextract import extract\n",
        "from tqdm import tqdm\n",
        "\n",
        "done = set()\n",
        "domains, subdomains, rejected = [], [], []\n",
        "\n",
        "for url in tqdm(urls):\n",
        "  url[1] = 'https://' + url[1]\n",
        "  ext = extract(url[1])\n",
        "  domain = ext.domain\n",
        "  subdomain = ext.subdomain\n",
        "  suffix = ext.suffix\n",
        "  if subdomain == \"\" or subdomain == \"www\":\n",
        "    if domain not in done:\n",
        "      domains.append(url)\n",
        "      done.add(domain)\n",
        "    else:\n",
        "       rejected.append(url)\n",
        "  else: subdomains.append(url)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000000/1000000 [00:09<00:00, 108923.88it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0yvtMvEqIzd",
        "colab_type": "code",
        "outputId": "be8693ed-cf2e-4da5-a9e5-89df317a0c96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"domains:\", len(domains), \"subdomains:\", len(subdomains), \"rejected:\", len(rejected))   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "domains: 216493 subdomains: 695988 rejected: 87519\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g71WKE5cs5QT",
        "colab_type": "code",
        "outputId": "88c084b0-b2d6-4935-afad-d7ec0e534eae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(domains[0:100])\n",
        "print(subdomains[0:100])\n",
        "print(rejected[0:100])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['1', 'https://netflix.com'], ['9', 'https://google.com'], ['10', 'https://microsoft.com'], ['13', 'https://windowsupdate.com'], ['17', 'https://live.com'], ['20', 'https://facebook.com'], ['23', 'https://nflxso.net'], ['24', 'https://doubleclick.net'], ['30', 'https://nflximg.com'], ['35', 'https://skype.com'], ['36', 'https://apple.com'], ['41', 'https://google-analytics.com'], ['44', 'https://bing.com'], ['45', 'https://office365.com'], ['46', 'https://amazonaws.com'], ['47', 'https://youtube.com'], ['48', 'https://www.googleapis.com'], ['52', 'https://digicert.com'], ['53', 'https://googleusercontent.com'], ['58', 'https://yahoo.com'], ['60', 'https://akamaiedge.net'], ['62', 'https://microsoftonline.com'], ['65', 'https://fbcdn.net'], ['68', 'https://windows.net'], ['69', 'https://googlesyndication.com'], ['73', 'https://office.com'], ['74', 'https://msn.com'], ['76', 'https://ytimg.com'], ['77', 'https://icloud.com'], ['78', 'https://googleadservices.com'], ['82', 'https://googletagmanager.com'], ['86', 'https://msedge.net'], ['91', 'https://akadns.net'], ['105', 'https://adnxs.com'], ['106', 'https://scorecardresearch.com'], ['107', 'https://outlook.com'], ['108', 'https://ggpht.com'], ['109', 'https://demdex.net'], ['111', 'https://amazon.com'], ['118', 'https://googlevideo.com'], ['119', 'https://twitter.com'], ['120', 'https://aaplimg.com'], ['128', 'https://adsrvr.org'], ['130', 'https://app-measurement.com'], ['133', 'https://rubiconproject.com'], ['137', 'https://moatads.com'], ['138', 'https://apple-dns.net'], ['139', 'https://gvt1.com'], ['140', 'https://2mdn.net'], ['143', 'https://amazon-adsystem.com'], ['144', 'https://instagram.com'], ['145', 'https://googletagservices.com'], ['150', 'https://crashlytics.com'], ['151', 'https://rlcdn.com'], ['153', 'https://cloudflare.com'], ['156', 'https://criteo.com'], ['157', 'https://bidswitch.net'], ['158', 'https://msftncsi.com'], ['160', 'https://adobe.com'], ['161', 'https://openx.net'], ['163', 'https://pubmatic.com'], ['165', 'https://agkn.com'], ['171', 'https://casalemedia.com'], ['172', 'https://advertising.com'], ['179', 'https://bluekai.com'], ['180', 'https://gvt2.com'], ['182', 'https://krxd.net'], ['184', 'https://akamai.net'], ['185', 'https://ntp.org'], ['187', 'https://akamaized.net'], ['192', 'https://taboola.com'], ['194', 'https://addthis.com'], ['200', 'https://everesttech.net'], ['201', 'https://mathtag.com'], ['203', 'https://tapad.com'], ['206', 'https://pki.goog'], ['207', 'https://adsafeprotected.com'], ['210', 'https://akamaihd.net'], ['221', 'https://linkedin.com'], ['222', 'https://whatsapp.net'], ['223', 'https://quantserve.com'], ['227', 'https://yimg.com'], ['234', 'https://sharepoint.com'], ['235', 'https://azureedge.net'], ['239', 'https://turn.com'], ['249', 'https://gmail.com'], ['252', 'https://adform.net'], ['262', 'https://nflxvideo.net'], ['266', 'https://exelator.com'], ['269', 'https://doubleverify.com'], ['271', 'https://outbrain.com'], ['278', 'https://sfx.ms'], ['279', 'https://fastly.net'], ['283', 'https://opendns.com'], ['287', 'https://crwdcntrl.net'], ['293', 'https://newrelic.com'], ['303', 'https://3lift.com'], ['304', 'https://pinterest.com'], ['305', 'https://spotxchange.com'], ['306', 'https://imrworldwide.com']]\n",
            "[['2', 'https://api-global.netflix.com'], ['3', 'https://prod.netflix.com'], ['4', 'https://push.prod.netflix.com'], ['5', 'https://ftl.netflix.com'], ['6', 'https://prod.ftl.netflix.com'], ['7', 'https://ichnaea.netflix.com'], ['8', 'https://nrdp.prod.ftl.netflix.com'], ['11', 'https://secure.netflix.com'], ['12', 'https://nrdp51-appboot.netflix.com'], ['14', 'https://ctldl.windowsupdate.com'], ['16', 'https://data.microsoft.com'], ['18', 'https://uiboot.netflix.com'], ['19', 'https://settings-win.data.microsoft.com'], ['21', 'https://safebrowsing.googleapis.com'], ['22', 'https://customerevents.netflix.com'], ['25', 'https://g.doubleclick.net'], ['26', 'https://1.nflxso.net'], ['27', 'https://events.data.microsoft.com'], ['28', 'https://nccp.netflix.com'], ['29', 'https://nrdp.nccp.netflix.com'], ['31', 'https://cdn-0.nflximg.com'], ['32', 'https://clients4.google.com'], ['33', 'https://googleads.g.doubleclick.net'], ['34', 'https://officeapps.live.com'], ['37', 'https://update.googleapis.com'], ['38', 'https://clientservices.googleapis.com'], ['39', 'https://edge.skype.com'], ['40', 'https://config.edge.skype.com'], ['42', 'https://nexusrules.officeapps.live.com'], ['49', 'https://v10.events.data.microsoft.com'], ['50', 'https://outlook.office365.com'], ['54', 'https://fonts.googleapis.com'], ['55', 'https://ocsp.digicert.com'], ['56', 'https://mp.microsoft.com'], ['57', 'https://login.live.com'], ['59', 'https://mtalk.google.com'], ['61', 'https://teams.microsoft.com'], ['63', 'https://graph.facebook.com'], ['64', 'https://login.microsoftonline.com'], ['66', 'https://weather.microsoft.com'], ['67', 'https://config.teams.microsoft.com'], ['72', 'https://tile-service.weather.microsoft.com'], ['75', 'https://clients1.google.com'], ['79', 'https://accounts.google.com'], ['80', 'https://aria.microsoft.com'], ['81', 'https://pipe.aria.microsoft.com'], ['84', 'https://play.googleapis.com'], ['87', 'https://stats.g.doubleclick.net'], ['88', 'https://adservice.google.com'], ['89', 'https://ls.apple.com'], ['90', 'https://i.ytimg.com'], ['92', 'https://itunes.apple.com'], ['93', 'https://pagead2.googlesyndication.com'], ['94', 'https://lh3.googleusercontent.com'], ['95', 'https://xx.fbcdn.net'], ['96', 'https://com.akadns.net'], ['97', 'https://play.google.com'], ['100', 'https://connect.facebook.net'], ['101', 'https://push.apple.com'], ['102', 'https://self.events.data.microsoft.com'], ['103', 'https://time-ios.apple.com'], ['104', 'https://securepubads.g.doubleclick.net'], ['110', 'https://dsp.mp.microsoft.com'], ['112', 'https://login.windows.net'], ['113', 'https://mobile.pipe.aria.microsoft.com'], ['114', 'https://dsce9.akamaiedge.net'], ['115', 'https://nexus.officeapps.live.com'], ['116', 'https://tpc.googlesyndication.com'], ['117', 'https://roaming.officeapps.live.com'], ['121', 'https://ad.doubleclick.net'], ['122', 'https://g.aaplimg.com'], ['124', 'https://sb.scorecardresearch.com'], ['125', 'https://clients.google.com'], ['126', 'https://go.microsoft.com'], ['127', 'https://android.clients.google.com'], ['129', 'https://dpm.demdex.net'], ['131', 'https://gsp64-ssl.ls.apple.com'], ['132', 'https://android.googleapis.com'], ['134', 'https://do.dsp.mp.microsoft.com'], ['135', 'https://prod.do.dsp.mp.microsoft.com'], ['136', 'https://ib.adnxs.com'], ['141', 'https://update.microsoft.com'], ['142', 'https://edge-mqtt.facebook.com'], ['146', 'https://fe.apple-dns.net'], ['148', 'https://odc.officeapps.live.com'], ['149', 'https://s0.2mdn.net'], ['152', 'https://init.itunes.apple.com'], ['154', 'https://match.adsrvr.org'], ['155', 'https://clients2.google.com'], ['159', 'https://e6858.dsce9.akamaiedge.net'], ['162', 'https://redirector.gvt1.com'], ['164', 'https://ajax.googleapis.com'], ['166', 'https://arc.msn.com'], ['167', 'https://iecvlist.microsoft.com'], ['168', 'https://x.bidswitch.net'], ['169', 'https://yt3.ggpht.com'], ['170', 'https://a.akamaiedge.net'], ['173', 'https://xp.apple.com'], ['174', 'https://vortex-win.data.microsoft.com'], ['175', 'https://cdnjs.cloudflare.com']]\n",
            "[['15', 'https://www.google.com'], ['43', 'https://www.facebook.com'], ['51', 'https://www.google-analytics.com'], ['70', 'https://www.bing.com'], ['71', 'https://www.youtube.com'], ['83', 'https://www.googletagmanager.com'], ['85', 'https://www.googleadservices.com'], ['98', 'https://facebook.net'], ['99', 'https://www.apple.com'], ['123', 'https://www.icloud.com'], ['147', 'https://www.googletagservices.com'], ['215', 'https://windows.com'], ['248', 'https://office.net'], ['286', 'https://criteo.net'], ['315', 'https://www.amazon.com'], ['341', 'https://www.msftconnecttest.com'], ['344', 'https://www.microsoft.com'], ['449', 'https://www.linkedin.com'], ['482', 'https://www.msn.com'], ['494', 'https://live.net'], ['618', 'https://chartbeat.com'], ['624', 'https://apple.news'], ['654', 'https://nflximg.net'], ['699', 'https://mozilla.net'], ['761', 'https://www.instagram.com'], ['767', 'https://adobe.io'], ['781', 'https://mozilla.org'], ['876', 'https://www.yahoo.com'], ['916', 'https://globalsign.net'], ['989', 'https://segment.com'], ['1001', 'https://yandex.net'], ['1102', 'https://www.msftncsi.com'], ['1117', 'https://www.storygize.net'], ['1187', 'https://cloudflare.net'], ['1252', 'https://hotjar.io'], ['1292', 'https://www.reddit.com'], ['1345', 'https://www.bizographics.com'], ['1501', 'https://www.netflix.com'], ['1551', 'https://www.paypalobjects.com'], ['1648', 'https://oath.cloud'], ['1664', 'https://weborama.fr'], ['1688', 'https://www.baidu.com'], ['1768', 'https://www.imdb.com'], ['1800', 'https://www.pinterest.com'], ['1874', 'https://typekit.com'], ['1946', 'https://whatsapp.com'], ['1961', 'https://www.paypal.com'], ['1987', 'https://bing.net'], ['2103', 'https://www.spotify.com'], ['2140', 'https://yahoo.co.jp'], ['2197', 'https://google.co.uk'], ['2199', 'https://www.dropbox.com'], ['2310', 'https://www.espn.com'], ['2344', 'https://yahoo.net'], ['2380', 'https://amazon.nl'], ['2388', 'https://brightcove.net'], ['2475', 'https://amazon.sa'], ['2483', 'https://www.redditstatic.com'], ['2490', 'https://www.nytimes.com'], ['2510', 'https://amazon.co.uk'], ['2516', 'https://www.cisco.com'], ['2528', 'https://stripe.network'], ['2578', 'https://www.summerhamster.com'], ['2589', 'https://www.lendingtree.com'], ['2594', 'https://www.goodreads.com'], ['2652', 'https://www.audible.com'], ['2669', 'https://www.google.co.uk'], ['2680', 'https://www.shopbop.com'], ['2690', 'https://www.bookdepository.com'], ['2703', 'https://rfihub.net'], ['2711', 'https://www.ssacdn.com'], ['2724', 'https://amazon.jobs'], ['2758', 'https://www.dpreview.com'], ['2759', 'https://ladsp.jp'], ['2762', 'https://www.amazon.jobs'], ['2820', 'https://google.com.ua'], ['2837', 'https://www.wholefoodsmarket.com'], ['2843', 'https://www.acx.com'], ['2846', 'https://cedexis.net'], ['2853', 'https://www.abebooks.com'], ['2859', 'https://www.alexa.com'], ['2913', 'https://www.pillpack.com'], ['2916', 'https://samsungcloudsolution.net'], ['2925', 'https://www.adobe.com'], ['2927', 'https://www.zappos.com'], ['2940', 'https://cashstaging.me'], ['2955', 'https://www.woot.com'], ['2958', 'https://grammarly.io'], ['2966', 'https://www.boxofficemojo.com'], ['2972', 'https://www.comixology.com'], ['2975', 'https://www.fabric.com'], ['2976', 'https://adnxs.net'], ['2978', 'https://www.createspace.com'], ['2995', 'https://www.eastdane.com'], ['3035', 'https://www.google.com.ua'], ['3062', 'https://www.pandora.com'], ['3073', 'https://google.de'], ['3089', 'https://yandex.ua'], ['3099', 'https://xiaomi.net'], ['3115', 'https://www.aboutamazon.com']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPs11PSZufdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/drive/My Drive/Site Data/domains.csv\", 'w') as csvfile:\n",
        "  csv_writer = csv.writer(csvfile)\n",
        "  csv_writer.writerows(domains)\n",
        "\n",
        "with open(\"/content/drive/My Drive/Site Data/subdomains.csv\", 'w') as csvfile:\n",
        "  csv_writer = csv.writer(csvfile)\n",
        "  csv_writer.writerows(subdomains)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45Z9rKY9wp6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/drive/My Drive/Site Data/domains.csv\") as csvfile:\n",
        "  csv_reader = csv.reader(csvfile)\n",
        "  domains = list(csv_reader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keeJX7ZIxuY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "domains[:100]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrmeKOqHcqAS",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBgIEbMng-2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "botk1MtFecca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -P /root/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS-J5IECepDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "EMBEDDING_FILE = '/root/input/GoogleNews-vectors-negative300.bin.gz' \n",
        "\n",
        "model = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True, limit=1000000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vF0gdvqgdZd",
        "colab_type": "code",
        "outputId": "77ce3bf8-55f5-4e6f-fe0c-369199fcf6df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "all_keys = set()\n",
        "for key in model.wv.vocab.keys():\n",
        "  all_keys.add(key)\n",
        "len(all_keys)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBmeMipwfNyk",
        "colab_type": "code",
        "outputId": "0e577e81-9dea-4509-f0ac-db77b2816d89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# This will also remove most of the names from dictionary along with not alphabetic keys and smaller keys\"\"\"\n",
        "\n",
        "dictionary = set()\n",
        "for key in model.wv.vocab.keys():\n",
        "  if(key.isalpha() and len(key) > 2 and key.lower() in all_keys): \n",
        "    dictionary.add(key.lower())\n",
        "len(dictionary)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104808"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPV837qoiRO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "\n",
        "with open('/content/drive/My Drive/dictionary.csv', 'w') as csvfile:\n",
        "  csv_writer = csv.writer(csvfile)\n",
        "  csv_writer.writerow(dictionary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffS9dyt2iFSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#common web terms\n",
        "AVOID = {'page', 'policy', 'url', 'load', 'unsupported', 'uses', 'cookies', 'error', 'content', 'support', 'skip', 'homepage', 'privacy', 'menu', 'site', 'sign', 'section', 'disabled', 'enabled', 'best', 'navigation', 'more', 'rights', 'supported', 'terms', 'signin', 'login', 'register', 'open', 'older', 'disable', 'failed', 'navigate', 'copyright', 'home', 'requested', 'help', 'know', 'jump', 'required', 'javascript', 'log', 'enable', 'reserved', 'policies', 'blocked', 'upgrade', 'anymore', 'copyrights', 'registered', 'condition', 'main', 'conditions', 'cookie', 'cookies', 'term'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJzHl31ncugN",
        "colab_type": "code",
        "outputId": "595d8edd-8f9d-406d-90f0-3353c76f6329",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from gensim.utils import tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def lemmatize(text):\n",
        "  \"\"\" lemmatize by, taking in account they don't differ much from original words after it \"\"\"\n",
        "\n",
        "  lt = (WordNetLemmatizer().lemmatize(text))\n",
        "  if lt not in dictionary: return text\n",
        "  sm = model.similarity(text, lt)\n",
        "  if sm >= 0.5 and sm <= 1: return lt \n",
        "  else: return text\n",
        "\n",
        "def fine(s):\n",
        "  \"\"\" Keep only string b/w length 3 and 45 as well as capitalize 3 char strings \"\"\"\n",
        "\n",
        "  if not s.isalpha(): return False\n",
        "  if len(s) < 3 or len(s) > 45: return False\n",
        "  if len(s) == 3 and s.islower(): return False\n",
        "  return True\n",
        "\n",
        "\n",
        "def mild_preprocess(content):\n",
        "  \"\"\"  1) tokenization\n",
        "       2) remove stopwords and small words\n",
        "       3) convert in lowercase \"\"\" \n",
        "\n",
        "  content = tokenize(content, deacc=True)\n",
        "  content = list(filter(fine, content))\n",
        "  content = [token.lower() for token in content]\n",
        "  content = [lemmatize(token) for token in content if token not in STOPWORDS and token in dictionary and token not in AVOID]\n",
        "  return content"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se5TL1tkkvsw",
        "colab_type": "text"
      },
      "source": [
        "# SCRAPPING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxRGrtyyyUne",
        "colab_type": "code",
        "outputId": "8823d46e-9d8d-475a-f052-d6afb9edf75c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip3 install selenium\n",
        "!pip3 install tldextract\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting selenium\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\u001b[K     |████████████████████████████████| 911kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n",
            "Installing collected packages: selenium\n",
            "Successfully installed selenium-3.141.0\n",
            "Collecting tldextract\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/0e/9ab599d6e78f0340bb1d1e28ddeacb38c8bb7f91a1b0eae9a24e9603782f/tldextract-2.2.2-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 1.7MB/s \n",
            "\u001b[?25hCollecting requests-file>=1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/77/86/cdb5e8eaed90796aa83a6d9f75cfbd37af553c47a291cd47bc410ef9bdb2/requests_file-1.5.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.6/dist-packages (from tldextract) (2.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from tldextract) (46.1.3)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tldextract) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from requests-file>=1.4->tldextract) (1.12.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->tldextract) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->tldextract) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.1.0->tldextract) (3.0.4)\n",
            "Installing collected packages: requests-file, tldextract\n",
            "Successfully installed requests-file-1.5.1 tldextract-2.2.2\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:10 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ Packages [91.7 kB]\n",
            "Get:11 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [37.4 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [66.8 kB]\n",
            "Get:17 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,813 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,376 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [52.4 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [8,505 B]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [844 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,205 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [19.8 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [8,158 B]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [8,286 B]\n",
            "Get:26 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [908 kB]\n",
            "Get:27 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [875 kB]\n",
            "Fetched 7,606 kB in 3s (2,523 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension adobe-flashplugin\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 108 not upgraded.\n",
            "Need to get 77.2 MB of archives.\n",
            "After this operation, 264 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 81.0.4044.122-0ubuntu0.18.04.1 [1,095 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 81.0.4044.122-0ubuntu0.18.04.1 [68.8 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 81.0.4044.122-0ubuntu0.18.04.1 [3,230 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 81.0.4044.122-0ubuntu0.18.04.1 [4,070 kB]\n",
            "Fetched 77.2 MB in 3s (24.4 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 144568 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_81.0.4044.122-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (81.0.4044.122-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_81.0.4044.122-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (81.0.4044.122-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_81.0.4044.122-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (81.0.4044.122-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_81.0.4044.122-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (81.0.4044.122-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (81.0.4044.122-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (81.0.4044.122-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (81.0.4044.122-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (81.0.4044.122-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZgEg6tw6RKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from bs4.element import Comment\n",
        "from tldextract import extract\n",
        "from selenium import webdriver\n",
        "import requests\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "browser = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "browser.set_page_load_timeout(10)\n",
        "\n",
        "headers = {\n",
        "\t'User-Agent': 'Mozilla/75.0',\n",
        "\t'Accept-Language': 'en-US,en;q=0.5'\n",
        "}\n",
        "\n",
        "SUFFICIENT = 70"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VYEpb_C6iTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tag_visible(element):\n",
        "  \"\"\" check visible tag \"\"\"\n",
        "\n",
        "  if element.parent.name in ['style', 'script', 'head', 'meta', '[document]']:\n",
        "      return False\n",
        "  if isinstance(element, Comment):\n",
        "      return False\n",
        "  return True\n",
        "\n",
        "def text_from_html(html):\n",
        "  \"\"\" Extract visible text from html body \"\"\"\n",
        "\n",
        "  soup = BeautifulSoup(html, 'html.parser')\n",
        "  text = soup.findAll(text=True)\n",
        "  visible_text = filter(tag_visible, text)  \n",
        "  return u\" \".join(t.strip() for t in visible_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4aRWn6d6sPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_about_url(html, url):\n",
        "  \"\"\"  return url of about page if exist \"\"\"\n",
        "  try:\n",
        "    domain = extract(url).domain.lower()  #fetch domain name of site\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "  \n",
        "    for link in soup.find_all('a'):\n",
        "      if link.get('href') != None and 'about' in link.get('href').lower() and domain in link.get('href').lower():\n",
        "        return link.get('href')\n",
        "  except:\n",
        "    return None\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wY9y3Xac6y3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_static_text_content(url):\n",
        "  \"\"\" scrap static content form url and preprocess it \"\"\"\n",
        "  content = []\n",
        "  try:\n",
        "    res = requests.get(url[1], headers=headers, verify=False, timeout=10)\n",
        "    content.extend(mild_preprocess(text_from_html(res.text)))\n",
        "    abt_url = get_about_url(res.text, url[1])\n",
        "    if abt_url != None:\n",
        "      res = requests.get(abt_url, headers=headers, verify=False, timeout=10)\n",
        "      content.extend(mild_preprocess(text_from_html(res.text)))\n",
        "    return [url[0], url[1], ' '.join(content)]\n",
        "  except:\n",
        "    return [url[0], url[1], ' '.join(content)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5bx9M8klcs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dynamic_text_content(url):\n",
        "  \"\"\" scrap dynamic content form url and preprocess it \"\"\"\n",
        "  content = []\n",
        "  try:\n",
        "    browser.get(url)\n",
        "    content.extend(mild_preprocess(text_from_html(browser.page_source)))\n",
        "    abt_url = get_about_url(browser.page_source, url)\n",
        "   \n",
        "    if abt_url != None:\n",
        "      browser.get(abt_url)\n",
        "      content.extend(mild_preprocess(text_from_html(browser.page_source)))\n",
        "    return content\n",
        "  except:\n",
        "    return content\n",
        "\n",
        "def get_text_content(url):\n",
        "  \"\"\" scrap text content from url \"\"\"\n",
        "  content = get_static_text_content(url[1])\n",
        "  if (len(content) < SUFFICIENT): content = get_dynamic_text_content(url[1])\n",
        "  return [url[0], url[1], ' '.join(content)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXK_bG7N6246",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#AVOID SCRAPPING DYNMAIC CONTENT WITH MULTIPROCESSING\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "def scrap(i, j):\n",
        "  with ProcessPoolExecutor(max_workers=50) as executor:\n",
        "      start = time.time()\n",
        "      futures = [ executor.submit(get_static_text_content, url) for url in domains[i:j]]\n",
        "      results = []\n",
        "      for result in tqdm(as_completed(futures)):\n",
        "          results.append(result.result())\n",
        "          with open(\"/content/drive/My Drive/Site Data/data_static_4.csv\", 'a') as csvfile:\n",
        "            csv_writer = csv.writer(csvfile)\n",
        "            csv_writer.writerow(result.result())\n",
        "          \n",
        "      end = time.time()\n",
        "      print(\"\\nTime Taken: {:.6f}s\".format(end-start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46VvfyqCmRy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import sys\n",
        "\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "\n",
        "with open(\"/content/drive/My Drive/Site Data/attempt.csv\") as csvfile:\n",
        "  csv_reader = csv.reader(csvfile)\n",
        "  results = list(csv_reader)\n",
        "\n",
        "attempt = result\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "for url in tqdm(attempt[5400:]):\n",
        "  result = get_text_content(url)\n",
        "  with open(\"/content/drive/My Drive/Site Data/data_dynamic4.csv\", 'a') as csvfile:\n",
        "    csv_writer = csv.writer(csvfile)\n",
        "    csv_writer.writerow(result)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}